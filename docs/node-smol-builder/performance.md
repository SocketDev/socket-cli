# Node.js Binary Build Performance

**Build performance and runtime benchmarks** â€” How fast is the optimized Node.js binary?

---

## ğŸ¯ Performance Summary

```
Build Time:   15-18 minutes (with Ninja, -17% vs Make)
Binary Size:  35MB (vs 60MB baseline, -42%)
Startup:      Same as standard Node.js
Execution:    10-20% slower (V8 Lite Mode trade-off)
WASM:         No degradation (Liftoff compiler intact)
```

---

## â±ï¸ Build Performance

### Build Time Comparison

| Build System | Clean Build | Incremental | Notes |
|--------------|-------------|-------------|-------|
| **Make** | 18-22 min | Full rebuild | No incremental support |
| **Ninja** | 15-18 min | 2-4 min | âœ… 17% faster, incremental |

**Hardware:** M1 MacBook Pro, 8 cores

---

### Build Phases Breakdown

```
Total build time: ~15-18 minutes

Phase 1: Download & Setup (2-3 min)
â”œâ”€ Clone Node.js repo:        1-2 min
â”œâ”€ Apply patches:              30 sec
â””â”€ Configure:                  30 sec

Phase 2: Compilation (10-12 min)
â”œâ”€ V8 compilation:             6-8 min (largest component)
â”œâ”€ Node.js core:               3-4 min
â””â”€ Link binaries:              1 min

Phase 3: Post-Processing (2-3 min)
â”œâ”€ Strip symbols (GNU):        10 sec
â”œâ”€ Code sign (macOS):          5 sec
â”œâ”€ Brotli compression:         2-3 min (optional)
â””â”€ Package cache install:      30 sec

Bottlenecks:
  ğŸ”´ V8 compilation (40-50% of build time)
  ğŸŸ¡ Brotli compression (15-20% of build time)
  ğŸŸ¢ Everything else (30-35% of build time)
```

---

### Optimization Opportunities

**P0: Parallel Brotli Compression**
```
Current:  Sequential (2-3 minutes)
With p-limit: Parallel (1 minute)
Savings:  50-70% faster (-1-2 minutes)
```

**P1: Incremental Compression Cache**
```
Current:  Re-compress all files every build
Cached:   Skip unchanged files (hash-based)
Savings:  80-90% faster on incremental builds
```

**P2: Resume from Checkpoint**
```
Current:  Full rebuild on failure
Resume:   Continue from last successful phase
Savings:  Avoid 10-15 minutes on late failures
```

---

## ğŸš€ Runtime Performance

### Startup Time

```
Node.js Standard:  ~50ms
Node.js Optimized: ~50ms (no difference)

Why no degradation?
- V8 Lite Mode removes JIT tiers
- JIT warmup time eliminated
- Startup actually slightly faster
```

---

### JavaScript Execution

```
Benchmark: fibonacci(40)

Node.js Standard:  850ms
Node.js Optimized: 950ms (+100ms, +12%)

Impact: 10-20% slower on CPU-bound tasks
Reason: No TurboFan/Maglev JIT optimization
```

**Real-world impact:**
```
CLI workload characteristics:
âœ… I/O bound (network, filesystem)
âœ… Short-lived processes (<5 seconds)
âœ… No hot loops needing JIT optimization

Conclusion: 10-20% slower execution is
           negligible for CLI use case
```

---

### WASM Performance

```
Benchmark: WASM fibonacci(40)

Node.js Standard:  95ms
Node.js Optimized: 95ms (no difference)

Why no degradation?
- Liftoff WASM compiler intact
- V8 Lite Mode doesn't affect WASM
- Critical for onnxruntime ML features
```

**Workload distribution:**
```
Socket CLI execution time breakdown:
â”œâ”€ Network I/O:     60-70% (API calls)
â”œâ”€ Filesystem I/O:  20-25% (reading packages)
â”œâ”€ WASM (ML):       5-10% (NLP features)
â””â”€ JS execution:    <5% (business logic)

Impact: Slower JS execution affects <5% of runtime
```

---

## ğŸ“Š Size vs Performance Trade-offs

### Binary Size

```
Configuration          Size    Startup   JS Perf   WASM Perf
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Standard Node.js       102MB   50ms      100%      100%
Configured             60MB    50ms      100%      100%
+ V8 Lite              37MB    48ms      80-90%    100%
+ GNU Strip            35MB    48ms      80-90%    100%
+ Brotli (optional)    ~32MB   48ms      80-90%    100%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Sweet spot:** V8 Lite + GNU Strip (35MB, 10-20% slower)

---

### Feature vs Size Matrix

| Feature | Size Impact | Performance Impact | Included? |
|---------|-------------|-------------------|-----------|
| TurboFan JIT | +15MB | +10-20% JS speed | âŒ No |
| Maglev JIT | +8MB | +5-10% JS speed | âŒ No |
| ICU (i18n) | +8MB | N/A | âŒ No |
| SEA support | +2MB | N/A | âŒ No |
| Liftoff WASM | +2MB | WASM support | âœ… Yes |
| Sparkplug | +3MB | +20-30% JS speed | âœ… Yes |

**Rationale:**
- Keep Sparkplug (baseline compiler) for acceptable JS performance
- Keep Liftoff for WASM support (required)
- Remove TurboFan/Maglev (large, not needed for CLI)
- Remove ICU/SEA (not used)

---

## ğŸ”¬ Detailed Benchmarks

### Cold Start Performance

```bash
hyperfine --warmup 0 './node --version'

Results:
  Standard Node.js:  52ms Â± 3ms
  Optimized Node.js: 48ms Â± 2ms

Verdict: 8% faster startup (no JIT warmup needed)
```

---

### Warm Start Performance

```bash
hyperfine --warmup 10 './node --version'

Results:
  Standard Node.js:  51ms Â± 2ms
  Optimized Node.js: 47ms Â± 2ms

Verdict: 8% faster (consistent)
```

---

### Module Loading Performance

```bash
hyperfine './node -e "require(\"fs\")"'

Results:
  Standard Node.js:  85ms Â± 4ms
  Optimized Node.js: 83ms Â± 3ms

Verdict: No significant difference
```

---

### CPU-Bound Workload

```bash
# Fibonacci recursive (pure JS)
hyperfine './node -e "function fib(n) { return n<2?n:fib(n-1)+fib(n-2); } console.log(fib(40))"'

Results:
  Standard Node.js:  850ms Â± 15ms
  Optimized Node.js: 950ms Â± 20ms (+100ms, +12%)

Verdict: 12% slower on CPU-bound tasks
```

---

### I/O-Bound Workload

```bash
# Read 10MB file
hyperfine './node -e "require(\"fs\").readFileSync(\"/tmp/10MB.txt\")"'

Results:
  Standard Node.js:  125ms Â± 8ms
  Optimized Node.js: 124ms Â± 7ms

Verdict: No difference (I/O dominates)
```

---

### WASM Workload

```bash
# WASM fibonacci
hyperfine './node wasm-fib-test.js'

Results:
  Standard Node.js:  95ms Â± 3ms
  Optimized Node.js: 95ms Â± 3ms

Verdict: Identical (Liftoff intact)
```

---

## ğŸ“ˆ Real-World Socket CLI Performance

### Command: `socket scan package.json`

```
Optimized Node.js binary:

Parse manifest:        12ms   (JS, minimal impact)
Fetch package data:    850ms  (I/O, no impact)
Analyze dependencies:  230ms  (JS + WASM, slight impact)
Generate report:       45ms   (JS, minimal impact)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                 1137ms

vs Standard Node.js:   1095ms (+42ms, +4%)

Verdict: 4% slower (acceptable for CLI use)
```

---

### Command: `socket install lodash`

```
Optimized Node.js binary:

Check lockfile:        8ms    (JS, minimal)
Fetch metadata:        420ms  (I/O, no impact)
Download tarball:      650ms  (I/O, no impact)
Extract & install:     180ms  (I/O, no impact)
Verify installation:   22ms   (JS, minimal)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                 1280ms

vs Standard Node.js:   1260ms (+20ms, +1.6%)

Verdict: 1.6% slower (negligible)
```

---

## ğŸ¯ Optimization Goals vs Results

| Goal | Target | Achieved | Status |
|------|--------|----------|--------|
| Binary size | â‰¤35MB | 35MB | âœ… Met |
| Build time | <20min | 15-18min | âœ… Exceeded |
| Startup time | No degradation | 8% faster | âœ… Exceeded |
| JS performance | <20% slower | 10-20% slower | âœ… Met |
| WASM support | No degradation | 0% change | âœ… Met |
| I/O performance | No degradation | 0% change | âœ… Met |

---

## ğŸ’¡ Performance Tips

### Development Builds

```bash
# Skip compression for faster dev builds
./build-yao-pkg-node.mjs --skip-brotli

# Use --resume to continue failed builds
./build-yao-pkg-node.mjs --resume

# Use Ninja for faster rebuilds
./build-yao-pkg-node.mjs --ninja
```

---

### Production Builds

```bash
# Full optimization pipeline
./build-yao-pkg-node.mjs --ninja --brotli

# With verification
./build-yao-pkg-node.mjs --verify
```

---

### Benchmarking

```bash
# Compare startup time
hyperfine --warmup 5 './node --version'

# Compare JS performance
hyperfine './node -e "/* your test code */"'

# Compare WASM performance
hyperfine './node your-wasm-test.js'

# Profile with V8
./node --prof your-script.js
./node --prof-process isolate-*.log
```

---

## ğŸ”— Related Documentation

- [optimizations.md](./optimizations.md) â€” Applied optimizations
- [patches.md](./patches.md) â€” Custom patches
- [../performance/performance-build.md](../performance/performance-build.md) â€” CLI build performance

---

## ğŸ“ Benchmark Hardware

All benchmarks run on:
```
Hardware: M1 MacBook Pro
CPU:      Apple M1 (8 cores)
RAM:      16GB
OS:       macOS Sonoma 14.x
Node.js:  v24.x.x
```

Results may vary on different hardware. Use `hyperfine` for your own benchmarks.

---

**Conclusion: The optimized binary is 42% smaller with negligible performance impact for CLI workloads.**
