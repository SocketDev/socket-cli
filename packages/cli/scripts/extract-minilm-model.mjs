/**
 * Generate minilm-sync.mjs for MiniLM model and tokenizer loading.
 *
 * This script creates the module exports expected by minilm-inference.mts.
 * The actual model and tokenizer data should be embedded here.
 *
 * Idempotent: Skips regeneration if file already exists (supports CI caching).
 */

import { existsSync, readFileSync, writeFileSync } from 'node:fs'
import path from 'node:path'
import { fileURLToPath } from 'node:url'

const __dirname = path.dirname(fileURLToPath(import.meta.url))
const rootPath = path.join(__dirname, '..')
const outputPath = path.join(rootPath, 'external/minilm-sync.mjs')

// Check if file already exists (supports CI cache).
if (existsSync(outputPath)) {
  try {
    const existing = readFileSync(outputPath, 'utf-8')
    // Verify it's the expected content (not corrupted).
    if (
      existing.includes('loadModelSync') &&
      existing.includes('loadTokenizerSync')
    ) {
      console.log(`✓ Using cached ${outputPath}`)
      process.exit(0)
    }
  } catch {}
  // Fall through to regenerate if verification failed.
}

// For now, create a placeholder that gracefully handles missing model data.
// In a complete implementation, this would embed the actual model binary.
const minilmSyncContent = `/**
 * MiniLM Model and Tokenizer Loader
 *
 * This file is AUTO-GENERATED by scripts/extract-minilm-model.mjs
 * DO NOT EDIT MANUALLY - changes will be overwritten on next build.
 *
 * Provides synchronous loaders for MiniLM model and tokenizer config.
 */

/**
 * Load MiniLM model bytes synchronously.
 * Returns model binary data for ONNX Runtime.
 *
 * Note: This is a placeholder. Production builds should embed the actual model.
 */
export function loadModelSync() {
  // Placeholder: In a production build, this would return the actual model binary.
  // For CI builds without the model, semantic matching will gracefully degrade
  // to pattern matching in handle-ask.mts.
  return new ArrayBuffer(0)
}

/**
 * Load tokenizer configuration synchronously.
 * Returns WordPiece tokenizer vocabulary and normalization rules.
 *
 * Note: This is a placeholder. Production builds should embed the actual tokenizer.
 */
export function loadTokenizerSync() {
  // Placeholder: In a production build, this would return:
  // { model: { vocab }, normalizer: { lowercase: true } }
  return {
    model: {
      vocab: {},
    },
    normalizer: {
      lowercase: true,
    },
  }
}
`

writeFileSync(outputPath, minilmSyncContent, 'utf-8')

console.log(`✓ Generated ${outputPath}`)
console.log(`✓ minilm-sync.mjs size: ${minilmSyncContent.length} bytes`)
console.log(
  'ℹ Note: minilm-sync.mjs is a placeholder. Production builds should embed the actual model data.',
)
