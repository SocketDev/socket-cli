import { describe, expect, it } from 'vitest'

import npmMalware from '../../../../src/src/commands/package/fixtures/npm_malware.json' with {
  type: 'json',
}
import {
  generateMarkdownReport,
  generateTextReport,
  preProcess,
} from '../../../../src/src/commands/package/output-purls-shallow-score.mts'

describe('package score output with malware detection', async () => {
  describe('malware and gptMalware alerts', () => {
    it('should display malware alerts in text report', () => {
      const { missing, rows } = preProcess(npmMalware.data, [])
      const txt = generateTextReport(rows, missing)

      // Check that the report contains both malware types.
      expect(txt).toContain('malware')
      expect(txt).toContain('gptMalware')
      expect(txt).toContain('[critical]')
      expect(txt).toContain('evil-test-package')

      // Verify the overall structure matches expected format.
      expect(txt).toMatchInlineSnapshot(`
        "
        [1mShallow Package Score[22m

        Please note: The listed scores are ONLY for the package itself. It does NOT
                     reflect the scores of any dependencies, transitive or otherwise.


        Package: [1mpkg:npm/evil-test-package@1.0.0[22m

        - Supply Chain Risk:  [31m  1[39m
        - Maintenance:       [32m10000[39m
        - Quality:           [32m10000[39m
        - Vulnerabilities:   [32m10000[39m
        - License:           [32m10000[39m
        - Alerts ([31m4[39m/[33m0[39m/0):     [31m[2m[critical] [22mgptMalware[39m, [31m[2m[critical] [22mmalware[39m, [31m[2m[high] [22mnetworkAccess[39m, and [31m[2m[high] [22mobfuscatedFile[39m
        "
      `)
    })

    it('should display malware alerts in markdown report', () => {
      const { missing, rows } = preProcess(npmMalware.data, [])
      const txt = generateMarkdownReport(rows, missing)

      // Check that the report contains both malware types.
      expect(txt).toContain('malware')
      expect(txt).toContain('gptMalware')
      expect(txt).toContain('[critical]')

      expect(txt).toMatchInlineSnapshot(`
        "# Shallow Package Report

        This report contains the response for requesting data on some package url(s).

        Please note: The listed scores are ONLY for the package itself. It does NOT
                     reflect the scores of any dependencies, transitive or otherwise.



        ## Package: pkg:npm/evil-test-package@1.0.0

        - Supply Chain Risk:    1
        - Maintenance:       10000
        - Quality:           10000
        - Vulnerabilities:   10000
        - License:           10000
        - Alerts (4/0/0):     [critical] gptMalware, [critical] malware, [high] networkAccess, and [high] obfuscatedFile"
      `)
    })

    it('should handle malware alerts with issueRules filtering', () => {
      // Test with only malware enabled.
      const dataWithMalwareOnly = JSON.parse(JSON.stringify(npmMalware.data))

      // Simulate issueRules filtering by setting actions on alerts.
      // When gptMalware is disabled, it would have action: 'ignore'.
      dataWithMalwareOnly[0].alerts[1].action = 'ignore' // gptMalware

      const { missing, rows } = preProcess(dataWithMalwareOnly, [])
      const txt = generateTextReport(rows, missing)

      // Should still show malware but not gptMalware if it's ignored.
      expect(txt).toContain('malware')
      // Note: gptMalware will still appear in the list but as ignored (not blocked).
    })

    it('should properly identify blocked alerts for malware', () => {
      const { missing: _missing, rows } = preProcess(npmMalware.data, [])

      // Check the processed data structure.
      expect(rows.size).toBe(1)
      const packageData = Array.from(rows.values())[0]

      // Verify alerts are properly categorized.
      expect(packageData.alerts).toBeDefined()

      // Find malware and gptMalware alerts.
      const alerts = Array.from(packageData.alerts.values())
      const malwareAlert = alerts.find((a: any) => a.type === 'malware')
      const gptMalwareAlert = alerts.find((a: any) => a.type === 'gptMalware')

      expect(malwareAlert).toBeDefined()
      expect(malwareAlert.severity).toBe('critical')

      expect(gptMalwareAlert).toBeDefined()
      expect(gptMalwareAlert.severity).toBe('critical')
    })
  })

  describe('config flag integration with malware detection', () => {
    it('should respect issueRules configuration for malware alerts', () => {
      // Simulate the config being passed with issueRules.
      const _issueRules = {
        malware: true,
        gptMalware: true,
      }

      // In actual implementation, the issueRules would filter alerts during API call
      // or during processing. Here we verify the data structure supports this.
      const { missing: _missing, rows } = preProcess(npmMalware.data, [])

      // Verify that both malware types are present when enabled.
      const packageData = Array.from(rows.values())[0]
      const alerts = Array.from(packageData.alerts.values())
      const hasRegularMalware = alerts.some((a: any) => a.type === 'malware')
      const hasGptMalware = alerts.some((a: any) => a.type === 'gptMalware')

      expect(hasRegularMalware).toBe(true)
      expect(hasGptMalware).toBe(true)
    })

    it('should format scores correctly for malware-infected packages', () => {
      const { missing: _missing, rows } = preProcess(npmMalware.data, [])
      const packageData = Array.from(rows.values())[0]

      // Verify scores are extremely low for malware package (or default 100 if undefined).
      // The preProcess function uses score || 100, converting 0 to 100.
      expect(packageData.score.supplyChain).toBe(0.01)
      expect(packageData.score.quality).toBe(100) // 0 becomes 100 due to || operator
      expect(packageData.score.maintenance).toBe(100) // 0 becomes 100 due to || operator
      expect(packageData.score.vulnerability).toBe(100) // 0 becomes 100 due to || operator
      expect(packageData.score.license).toBe(100) // 0 becomes 100 due to || operator
    })
  })
})
