/**
 * ONNX Runtime wrapper for MiniLM inference.
 *
 * This file is AUTO-GENERATED by scripts/extract-onnx-runtime.mjs
 * DO NOT EDIT MANUALLY - changes will be overwritten on next build.
 *
 * Re-exports onnxruntime-web for use in MiniLM embedding pipeline.
 */

import ort from 'onnxruntime-web'

export const InferenceSession = ort.InferenceSession
export const Tensor = ort.Tensor

export default ort
